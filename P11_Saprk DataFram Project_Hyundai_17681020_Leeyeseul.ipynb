{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-2.4.5-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Hyunadi').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Hyundai Motor Company.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2015, 3, 2, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0)\n",
      "Row(Date=datetime.datetime(2015, 3, 3, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=500)\n",
      "Row(Date=datetime.datetime(2015, 3, 4, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0)\n",
      "Row(Date=datetime.datetime(2015, 3, 5, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0)\n",
      "Row(Date=datetime.datetime(2015, 3, 6, 0, 0), Open=51.139999, High=51.139999, Low=49.599998, Close=49.599998, Adj Close=39.839649, Volume=31500)\n"
     ]
    }
   ],
   "source": [
    "for row in df.head(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|              High|              Low|            Close|        Adj Close|           Volume|\n",
      "+-------+------------------+------------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1259|              1259|             1259|             1259|             1259|             1259|\n",
      "|   mean|39.494741768069844| 39.54116751072275|39.40830014138199| 39.4606194495631| 35.2082239046863| 950.833995234313|\n",
      "| stddev| 6.559876473950293|6.5369870174235025|6.576103128354254|6.551472221533396|4.286853086778444|4626.548348592509|\n",
      "|    min|             25.25|             25.25|            25.25|            25.25|        23.582779|                0|\n",
      "|    max|              58.5|              58.5|             58.5|             58.5|        46.988308|            97900|\n",
      "+-------+------------------+------------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+------+\n",
      "|summary|    Open|    High|     Low|   Close|Volume|\n",
      "+-------+--------+--------+--------+--------+------+\n",
      "|  count|1,259.00|1,259.00|1,259.00|1,259.00|  1259|\n",
      "|   mean|   39.49|   39.54|   39.41|   39.46|   950|\n",
      "| stddev|    6.56|    6.54|    6.58|    6.55|  4626|\n",
      "|    min|   25.25|   25.25|   25.25|   25.25|     0|\n",
      "|    max|   58.50|   58.50|   58.50|   58.50| 97900|\n",
      "+-------+--------+--------+--------+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(result['summary'],\n",
    "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "              format_number(result['High'].cast('float'),2).alias('High'),\n",
    "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "              result['Volume'].cast('int').alias('Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn(\"HV ration\", df['High']/df['Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           HV ration|\n",
      "+--------------------+\n",
      "|                null|\n",
      "|         0.097900002|\n",
      "|                null|\n",
      "|                null|\n",
      "|0.001623492031746...|\n",
      "|0.004242734957264957|\n",
      "|                null|\n",
      "|           0.0124375|\n",
      "|               0.245|\n",
      "|                null|\n",
      "| 0.01745517206896552|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "|         0.127299995|\n",
      "|0.021956521739130434|\n",
      "| 0.01596774193548387|\n",
      "|                null|\n",
      "|                null|\n",
      "|                null|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('HV ration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2015, 3, 2, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0),\n",
       " Row(Date=datetime.datetime(2015, 3, 3, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=500),\n",
       " Row(Date=datetime.datetime(2015, 3, 4, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0),\n",
       " Row(Date=datetime.datetime(2015, 3, 5, 0, 0), Open=48.950001, High=48.950001, Low=48.950001, Close=48.950001, Adj Close=39.317558, Volume=0),\n",
       " Row(Date=datetime.datetime(2015, 3, 6, 0, 0), Open=51.139999, High=51.139999, Low=49.599998, Close=49.599998, Adj Close=39.839649, Volume=31500),\n",
       " Row(Date=datetime.datetime(2015, 3, 9, 0, 0), Open=49.639999, High=49.639999, Low=49.639999, Close=49.639999, Adj Close=39.871784, Volume=11700),\n",
       " Row(Date=datetime.datetime(2015, 3, 10, 0, 0), Open=49.639999, High=49.639999, Low=49.639999, Close=49.639999, Adj Close=39.871784, Volume=0),\n",
       " Row(Date=datetime.datetime(2015, 3, 11, 0, 0), Open=48.5, High=49.75, Low=48.5, Close=48.5, Adj Close=38.956116, Volume=4000),\n",
       " Row(Date=datetime.datetime(2015, 3, 12, 0, 0), Open=49.0, High=49.0, Low=49.0, Close=49.0, Adj Close=39.357723, Volume=200),\n",
       " Row(Date=datetime.datetime(2015, 3, 13, 0, 0), Open=49.0, High=49.0, Low=49.0, Close=49.0, Adj Close=39.357723, Volume=0),\n",
       " Row(Date=datetime.datetime(2015, 3, 16, 0, 0), Open=50.619999, High=50.619999, Low=50.0, Close=50.0, Adj Close=40.160942, Volume=2900)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2015, 4, 27, 0, 0), Open=58.5, High=58.5, Low=58.5, Close=58.5, Adj Close=46.988308, Volume=400)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2015, 4, 27, 0, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|      avg(Close)|\n",
      "+----------------+\n",
      "|39.4606194495631|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(mean('Close')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max,min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|max(High)|min(High)|\n",
      "+---------+---------+\n",
      "|     58.5|    25.25|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('High'),min('High')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"Close < 28\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Close']<28).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.filter(df['Close']<28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Close)|\n",
      "+------------+\n",
      "|          38|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(count('Close')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.26290706910247"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(df['High']>30).count()*1.0/df.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "| corr(High, Volume)|\n",
      "+-------------------+\n",
      "|0.05385715370896034|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('High','Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeardf = df.withColumn('Year',year(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = yeardf.groupBy('Year').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+---------+\n",
      "|Year| max(Low)|max(High)|\n",
      "+----+---------+---------+\n",
      "|2018|     47.5|     47.5|\n",
      "|2015|     58.5|     58.5|\n",
      "|2019|     45.0|     45.0|\n",
      "|2020|    33.98|    33.98|\n",
      "|2016|46.349998|46.349998|\n",
      "|2017|49.650002|     50.0|\n",
      "+----+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_df.select('Year','max(Low)','max(High)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df.withColumn('Month',month('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthavga = monthdf.select('Month','Open','Close').groupBy('Month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+\n",
      "|Month|         avg(Open)|        avg(Close)|\n",
      "+-----+------------------+------------------+\n",
      "|    1|  37.9899020490196| 37.86813727450979|\n",
      "|    2|37.343645708333334|37.485104041666666|\n",
      "|    3|41.529541339449544| 41.48192671559634|\n",
      "|    4| 41.29980534951457|  41.2720383300971|\n",
      "|    5| 42.18158863551404| 42.16551389719628|\n",
      "|    6|41.648130467289704| 41.61887816822429|\n",
      "|    7| 39.34276150476192|39.319999609523826|\n",
      "|    8| 38.29526786607141|  38.2748214642857|\n",
      "|    9|39.135148415841606|39.105148396039624|\n",
      "|   10| 38.81639663963962|38.802522756756744|\n",
      "|   11| 38.55320406796118| 38.47941765048545|\n",
      "|   12| 37.48766983495146| 37.34815525242719|\n",
      "+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthavga.select('Month','avg(Open)','avg(Close)').orderBy('Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
