{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init('/home/ubuntu/spark-2.4.5-bin-hadoop2.7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('apple').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('appl_stock.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039)\n",
      "Row(Date=datetime.datetime(2010, 1, 5, 0, 0), Open=214.599998, High=215.589994, Low=213.249994, Close=214.379993, Volume=150476200, Adj Close=27.774976000000002)\n",
      "Row(Date=datetime.datetime(2010, 1, 6, 0, 0), Open=214.379993, High=215.23, Low=210.750004, Close=210.969995, Volume=138040000, Adj Close=27.333178000000004)\n",
      "Row(Date=datetime.datetime(2010, 1, 7, 0, 0), Open=211.75, High=212.000006, Low=209.050005, Close=210.58, Volume=119282800, Adj Close=27.28265)\n",
      "Row(Date=datetime.datetime(2010, 1, 8, 0, 0), Open=210.299994, High=212.000006, Low=209.06000500000002, Close=211.98000499999998, Volume=111902700, Adj Close=27.464034)\n"
     ]
    }
   ],
   "source": [
    "for row in df.head(5):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+-----------------+-------------------+------------------+\n",
      "|summary|              Open|              High|               Low|            Close|             Volume|         Adj Close|\n",
      "+-------+------------------+------------------+------------------+-----------------+-------------------+------------------+\n",
      "|  count|              1762|              1762|              1762|             1762|               1762|              1762|\n",
      "|   mean| 313.0763111589103| 315.9112880164581| 309.8282405079457|312.9270656379113|9.422577587968218E7| 75.00174115607275|\n",
      "| stddev|185.29946803981522|186.89817686485767|183.38391664371008|185.1471036170943|6.020518776592709E7| 28.57492972179906|\n",
      "|    min|              90.0|         90.699997|         89.470001|        90.279999|           11475900|         24.881912|\n",
      "|    max|        702.409988|        705.070023|        699.569977|       702.100021|          470249500|127.96609099999999|\n",
      "+-------+------------------+------------------+------------------+-----------------+-------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import format_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------+--------+--------+---------+\n",
      "|summary|    Open|    High|     Low|   Close|   Volume|\n",
      "+-------+--------+--------+--------+--------+---------+\n",
      "|  count|1,762.00|1,762.00|1,762.00|1,762.00|     1762|\n",
      "|   mean|  313.08|  315.91|  309.83|  312.93|     null|\n",
      "| stddev|  185.30|  186.90|  183.38|  185.15|     null|\n",
      "|    min|   90.00|   90.70|   89.47|   90.28| 11475900|\n",
      "|    max|  702.41|  705.07|  699.57|  702.10|470249500|\n",
      "+-------+--------+--------+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(result['summary'],\n",
    "              format_number(result['Open'].cast('float'),2).alias('Open'),\n",
    "              format_number(result['High'].cast('float'),2).alias('High'),\n",
    "              format_number(result['Low'].cast('float'),2).alias('Low'),\n",
    "              format_number(result['Close'].cast('float'),2).alias('Close'),\n",
    "              result['Volume'].cast('int').alias('Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- summary: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.describe().printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.withColumn(\"HV ration\", df['High']/df['Volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           HV ration|\n",
      "+--------------------+\n",
      "|1.737793286041590...|\n",
      "|1.432718223878593...|\n",
      "|1.559185743262822...|\n",
      "|1.777288980473295...|\n",
      "|1.894503045949740...|\n",
      "|1.843239827133528...|\n",
      "|1.411500428288146...|\n",
      "|1.392525367557254...|\n",
      "|1.944679270213955...|\n",
      "|1.424753661031169E-6|\n",
      "|1.179111006515548...|\n",
      "|1.408471832522860...|\n",
      "|1.402998948951121...|\n",
      "|9.412910884908904E-7|\n",
      "|7.683215757986584E-7|\n",
      "|4.578412734118504E-7|\n",
      "|4.889907419641508E-7|\n",
      "|7.004672644896166E-7|\n",
      "|6.491419575900331E-7|\n",
      "|1.045505632661596E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select('HV ration').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2010, 1, 4, 0, 0), Open=213.429998, High=214.499996, Low=212.38000099999996, Close=214.009998, Volume=123432400, Adj Close=27.727039),\n",
       " Row(Date=datetime.datetime(2010, 1, 5, 0, 0), Open=214.599998, High=215.589994, Low=213.249994, Close=214.379993, Volume=150476200, Adj Close=27.774976000000002),\n",
       " Row(Date=datetime.datetime(2010, 1, 6, 0, 0), Open=214.379993, High=215.23, Low=210.750004, Close=210.969995, Volume=138040000, Adj Close=27.333178000000004),\n",
       " Row(Date=datetime.datetime(2010, 1, 7, 0, 0), Open=211.75, High=212.000006, Low=209.050005, Close=210.58, Volume=119282800, Adj Close=27.28265),\n",
       " Row(Date=datetime.datetime(2010, 1, 8, 0, 0), Open=210.299994, High=212.000006, Low=209.06000500000002, Close=211.98000499999998, Volume=111902700, Adj Close=27.464034),\n",
       " Row(Date=datetime.datetime(2010, 1, 11, 0, 0), Open=212.79999700000002, High=213.000002, Low=208.450005, Close=210.11000299999998, Volume=115557400, Adj Close=27.221758),\n",
       " Row(Date=datetime.datetime(2010, 1, 12, 0, 0), Open=209.18999499999998, High=209.76999500000002, Low=206.419998, Close=207.720001, Volume=148614900, Adj Close=26.91211),\n",
       " Row(Date=datetime.datetime(2010, 1, 13, 0, 0), Open=207.870005, High=210.92999500000002, Low=204.099998, Close=210.650002, Volume=151473000, Adj Close=27.29172),\n",
       " Row(Date=datetime.datetime(2010, 1, 14, 0, 0), Open=210.11000299999998, High=210.45999700000002, Low=209.020004, Close=209.43, Volume=108223500, Adj Close=27.133657),\n",
       " Row(Date=datetime.datetime(2010, 1, 15, 0, 0), Open=210.92999500000002, High=211.59999700000003, Low=205.869999, Close=205.93, Volume=148516900, Adj Close=26.680197999999997),\n",
       " Row(Date=datetime.datetime(2010, 1, 19, 0, 0), Open=208.330002, High=215.18999900000003, Low=207.240004, Close=215.039995, Volume=182501900, Adj Close=27.860484999999997)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.datetime(2012, 9, 21, 0, 0), Open=702.409988, High=705.070023, Low=699.3599849999999, Close=700.089989, Volume=142897300, Adj Close=91.09278)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2012, 9, 21, 0, 0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy(df['High'].desc()).head(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|312.9270656379113|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(mean('Close')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max,min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|  470249500|   11475900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('Volume'),min('Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(\"Close < 100\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.filter(df['Close']<100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.filter(df['Close']<100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|count(Close)|\n",
      "+------------+\n",
      "|         163|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(count('Close')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.71509648127127"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.filter(df['High']>120).count()*1.0/df.count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|corr(High, Volume)|\n",
      "+------------------+\n",
      "|0.4144024424820674|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(corr('High','Volume')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeardf = df.withColumn('Year',year(df['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_df = yeardf.groupBy('Year').max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+------------------+\n",
      "|Year|         max(Low)|         max(High)|\n",
      "+----+-----------------+------------------+\n",
      "|2015|       131.399994|134.53999299999998|\n",
      "|2013|566.4100269999999|        575.139999|\n",
      "|2014|       644.470024|        651.259979|\n",
      "|2012|       699.569977|        705.070023|\n",
      "|2016|       117.449997|        118.690002|\n",
      "|2010|       325.099991|            326.66|\n",
      "|2011|       415.990002|426.69999299999995|\n",
      "+----+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_df.select('Year','max(Low)','max(High)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthdf = df.withColumn('Month',month('Date'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthavga = monthdf.select('Month','Open','Close').groupBy('Month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+\n",
      "|Month|         avg(Open)|        avg(Close)|\n",
      "+-----+------------------+------------------+\n",
      "|    1|322.90628572142856|322.20971425714276|\n",
      "|    2| 320.7831106888889| 321.3595563037038|\n",
      "|    3| 332.8893468300655|332.91156731372547|\n",
      "|    4| 341.0048631506845|340.51041081506827|\n",
      "|    5|351.59870752380965|351.62102085714304|\n",
      "|    6|288.75166685333335|      288.12546566|\n",
      "|    7| 281.2487831148649|281.72216211486483|\n",
      "|    8| 300.2057422967742| 300.4385809612901|\n",
      "|    9| 301.3590970763887| 301.0763195902777|\n",
      "|   10| 308.5571721973687|308.30552563157886|\n",
      "|   11|  306.612237797203| 306.2725174895104|\n",
      "|   12|302.76953076510085|302.35053626845644|\n",
      "+-----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "monthavga.select('Month','avg(Open)','avg(Close)').orderBy('Month').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
